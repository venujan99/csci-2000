{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scipy - High-Level Scientific Computing\n",
    "__Authors:__ _Adrien Chauve, Andre Espaze, Emmanuelle Gouillart, Gaël Varoquaux, Ralf Gommers_\n",
    "## Scipy\n",
    "The scipy package contains various toolboxes dedicated to common issues in scientific computing. Its different submodules correspond to different applications, such as interpolation, integration, optimization, image processing, statistics, special functions, etc.\n",
    "\n",
    "`Scipy` can be compared to other standard scientific-computing libraries, such as the GSL (_GNU Scientific Library_ for `C` and `C++`), or `Matlab`’s toolboxes. `Scipy` is the core package for scientific routines in Python; it is meant to operate efficiently on numpy arrays, so that `numpy` and `scipy` work hand in hand.\n",
    "\n",
    "Before implementing a routine, it is worth checking if the desired data processing is not already implemented in `Scipy`. As non-professional programmers, scientists often tend to re-invent the wheel, which leads to buggy, non-optimal, difficult-to-share and unmaintainable code. By contrast, `Scipy`‘s routines are optimized and tested, and should therefore be used when possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`scipy` is composed of task-specific sub-modules:\n",
    "\n",
    "Sub-module | Description\n",
    "--- | ---\n",
    "[`scipy.cluster`](http://docs.scipy.org/doc/scipy/reference/cluster.html#module-scipy.cluster) | Vector quantization / Kmeans\n",
    "[`scipy.constants`](http://docs.scipy.org/doc/scipy/reference/constants.html#module-scipy.constants) | Physical and mathematical constants\n",
    "[`scipy.fftpack`](http://docs.scipy.org/doc/scipy/reference/fftpack.html#module-scipy.fftpack) | Fourier transform\n",
    "[`scipy.integrate`](http://docs.scipy.org/doc/scipy/reference/integrate.html#module-scipy.integrate) | Integration routines\n",
    "[`scipy.interpolate`](http://docs.scipy.org/doc/scipy/reference/interpolate.html#module-scipy.interpolate) | Interpolation\n",
    "[`scipy.io`](http://docs.scipy.org/doc/scipy/reference/io.html#module-scipy.io) | Data input and output\n",
    "[`scipy.linalg`](http://docs.scipy.org/doc/scipy/reference/linalg.html#module-scipy.linalg) | Linear algebra routines\n",
    "[`scipy.ndimage`](http://docs.scipy.org/doc/scipy/reference/ndimage.html#module-scipy.ndimage) | n-dimensional image package\n",
    "[`scipy.odr`](http://docs.scipy.org/doc/scipy/reference/odr.html#module-scipy.odr) | Orthogonal distance regression\n",
    "[`scipy.optimize`](http://docs.scipy.org/doc/scipy/reference/optimize.html#module-scipy.optimize) | Optimization\n",
    "[`scipy.signal`](http://docs.scipy.org/doc/scipy/reference/signal.html#module-scipy.signal) | Signal processing\n",
    "[`scipy.sparse`](http://docs.scipy.org/doc/scipy/reference/sparse.html#module-scipy.sparse) | Sparse matrices\n",
    "[`scipy.spatial`](http://docs.scipy.org/doc/scipy/reference/spatial.html#module-scipy.spatial) | Spatial data structures and algorithms\n",
    "[`scipy.special`](http://docs.scipy.org/doc/scipy/reference/special.html#module-scipy.special) | Any special mathematical functions\n",
    "[`scipy.stats`](http://docs.scipy.org/doc/scipy/reference/stats.html#module-scipy.stats) | Statistics\n",
    "\n",
    "They all depend on numpy, but are mostly independent of each other. The standard way of importing `Numpy` and these `Scipy` modules is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats  # same for other sub-modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main scipy namespace mostly contains functions that are really `numpy` functions (try `scipy.cos` is `np.cos`). Those are exposed for historical reasons only; there’s usually no reason to use `import scipy` in your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. File input/output: [`scipy.io`](http://docs.scipy.org/doc/scipy/reference/io.html#module-scipy.io)\n",
    "* Loading and saving `Matlab` files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy import io as spio\n",
    "a = np.ones((3, 3))\n",
    "spio.savemat('file.mat', {'a': a}) # savemat expects a dictionary\n",
    "data = spio.loadmat('file.mat', struct_as_record=True)\n",
    "data['a']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Reading images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy import misc\n",
    "misc.imread('images/fname.png')    \n",
    "\n",
    "# Matplotlib also has a similar function\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imread('images/fname.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See also:\n",
    "* Load text files: [`numpy.loadtxt()`](http://docs.scipy.org/doc/numpy/reference/generated/numpy.loadtxt.html#numpy.loadtxt)/[`numpy.savetxt()`](http://docs.scipy.org/doc/numpy/reference/generated/numpy.savetxt.html#numpy.savetxt)\n",
    "* Clever loading of text/csv files: [`numpy.genfromtxt()`](http://docs.scipy.org/doc/numpy/reference/generated/numpy.genfromtxt.html#numpy.genfromtxt)/`numpy.recfromcsv()`\n",
    "* Fast and efficient, but numpy-specific, binary format: [`numpy.save()`](http://docs.scipy.org/doc/numpy/reference/generated/numpy.save.html#numpy.save)/[`numpy.load()`](http://docs.scipy.org/doc/numpy/reference/generated/numpy.load.html#numpy.load)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Special functions: [`scipy.special`](http://docs.scipy.org/doc/scipy/reference/special.html#module-scipy.special)\n",
    "Special functions are transcendental functions. The docstring of the [`scipy.special`](http://docs.scipy.org/doc/scipy/reference/special.html#module-scipy.special) module is well-written, so we won’t list all functions here. Frequently used ones are:\n",
    "* Bessel function, such as `scipy.special.jn()` (nth integer order Bessel function)\n",
    "* Elliptic function (`scipy.special.ellipj()` for the Jacobian elliptic function, ...)\n",
    "* Gamma function: `scipy.special.gamma()`, also note `scipy.special.gammaln()` which will give the log of Gamma to a higher numerical precision.\n",
    "* Erf, the area under a Gaussian curve: `scipy.special.erf()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Linear algebra operations: [`scipy.linalg`](http://docs.scipy.org/doc/scipy/reference/linalg.html#module-scipy.linalg)\n",
    "The [`scipy.linalg`](http://docs.scipy.org/doc/scipy/reference/linalg.html#module-scipy.linalg) module provides standard linear algebra operations, relying on an underlying efficient implementation (`BLAS`, `LAPACK`).\n",
    "\n",
    "* The [`scipy.linalg.det()`](http://docs.scipy.org/doc/scipy/reference/generated/scipy.linalg.det.html#scipy.linalg.det) function computes the determinant of a square matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy import linalg\n",
    "arr = np.array([[1, 2],\n",
    "                [3, 4]])\n",
    "linalg.det(arr)\n",
    "\n",
    "arr = np.array([[3, 2],\n",
    "                [6, 4]])\n",
    "linalg.det(arr)\n",
    "\n",
    "linalg.det(np.ones((3, 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* The [`scipy.linalg.inv()`](http://docs.scipy.org/doc/scipy/reference/generated/scipy.linalg.inv.html#scipy.linalg.inv) function computes the inverse of a square matrix:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "arr = np.array([[1, 2],\n",
    "                [3, 4]])\n",
    "iarr = linalg.inv(arr)\n",
    "iarr\n",
    "\n",
    "\n",
    "np.allclose(np.dot(arr, iarr), np.eye(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;Finally computing the inverse of a singular matrix (its determinant is zero) will raise `LinAlgError`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "arr = np.array([[3, 2],\n",
    "                [6, 4]])\n",
    "linalg.inv(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* More advanced operations are available, for example singular-value decomposition (SVD):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arr = np.arange(9).reshape((3, 3)) + np.diag([1, 0, 1])\n",
    "uarr, spec, vharr = linalg.svd(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;The resulting array spectrum is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;The original matrix can be re-composed by matrix multiplication of the outputs of `svd` with `np.dot`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sarr = np.diag(spec)\n",
    "svd_mat = uarr.dot(sarr).dot(vharr)\n",
    "np.allclose(svd_mat, arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVD is commonly used in statistics and signal processing. Many other standard decompositions (QR, LU, Cholesky, Schur), as well as solvers for linear systems, are available in [`scipy.linalg`](http://docs.scipy.org/doc/scipy/reference/linalg.html#module-scipy.linalg)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Fast Fourier transforms: [`scipy.fftpack`](http://docs.scipy.org/doc/scipy/reference/fftpack.html#module-scipy.fftpack)\n",
    "The [`scipy.fftpack`](http://docs.scipy.org/doc/scipy/reference/fftpack.html#module-scipy.fftpack) module allows to compute _fast Fourier transforms_. As an illustration, a (noisy) input signal may look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time_step = 0.02\n",
    "period = 5.\n",
    "time_vec = np.arange(0, 20, time_step)\n",
    "sig = np.sin(2 * np.pi / period * time_vec) + \\\n",
    "      0.5 * np.random.randn(time_vec.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The observer doesn’t know the signal frequency, only the sampling time step of the signal `sig`. The signal is supposed to come from a real function so the Fourier transform will be symmetric. The [`scipy.fftpack.fftfreq()`](http://docs.scipy.org/doc/scipy/reference/generated/scipy.fftpack.fftfreq.html#scipy.fftpack.fftfreq) function will generate the sampling frequencies and [`scipy.fftpack.fft()`](http://docs.scipy.org/doc/scipy/reference/generated/scipy.fftpack.fft.html#scipy.fftpack.fft) will compute the fast Fourier transform:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import fftpack\n",
    "sample_freq = fftpack.fftfreq(sig.size, d=time_step)\n",
    "sig_fft = fftpack.fft(sig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the resulting power is symmetric, only the positive part of the spectrum needs to be used for finding the frequency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pidxs = np.where(sample_freq > 0)\n",
    "freqs, power = sample_freq[pidxs], np.abs(sig_fft)[pidxs]\n",
    "freq = freqs[power.argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pylab as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(freqs, power)\n",
    "plt.xlabel('Frequency [Hz]')\n",
    "plt.ylabel('plower')\n",
    "axes = plt.axes([0.3, 0.3, 0.5, 0.5])\n",
    "plt.title('Peak frequency')\n",
    "plt.plot(freqs[:8], power[:8])\n",
    "plt.setp(axes, yticks=[])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The signal frequency can be found by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "freq = freqs[power.argmax()]\n",
    "np.allclose(freq, 1./period)  # check that correct freq is found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the high-frequency noise will be removed from the Fourier transformed signal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sig_fft[np.abs(sample_freq) > freq] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting filtered signal can be computed by the [`scipy.fftpack.ifft()`](http://docs.scipy.org/doc/scipy/reference/generated/scipy.fftpack.ifft.html#scipy.fftpack.ifft) function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "main_sig = fftpack.ifft(sig_fft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result can be viewed with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()    \n",
    "plt.plot(time_vec, sig)    \n",
    "plt.plot(time_vec, main_sig, linewidth=3)    \n",
    "plt.xlabel('Time [s]')    \n",
    "plt.ylabel('Amplitude')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy also has an implementation of FFT ([`numpy.fft`](http://docs.scipy.org/doc/numpy/reference/routines.fft.html#module-numpy.fft)). However, in general the `scipy` one should be preferred, as it uses more efficient underlying implementations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Worked Example: Crude periodicity finding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Discover the periods in data/populations.txt\n",
    "\"\"\"\n",
    "\n",
    "data = np.loadtxt('data/populations.txt')\n",
    "years = data[:, 0]\n",
    "populations = data[:, 1:]\n",
    "\n",
    "ft_populations = np.fft.fft(populations, axis=0)\n",
    "frequencies = np.fft.fftfreq(populations.shape[0], years[1] - years[0])\n",
    "periods = 1 / frequencies\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(years, populations * 1e-3)\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Population number ($\\cdot10^3$)')\n",
    "plt.legend(['hare', 'lynx', 'carrot'], loc=1)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(periods, abs(ft_populations) * 1e-3, 'o')\n",
    "plt.xlim(0, 22)\n",
    "plt.xlabel('Period')\n",
    "plt.ylabel('Power ($\\cdot10^3$)')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# There's probably a period of around 10 years (obvious from the\n",
    "# plot), but for this crude a method, there's not enough data to say\n",
    "# much more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Worked example: Gaussian image blur\n",
    "Convolution:\n",
    "<img src=\"images/conv1.png\" />\n",
    "<img src=\"images/conv2.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Simple image blur by convolution with a Gaussian kernel\n",
    "\"\"\"\n",
    "\n",
    "# read image\n",
    "img = plt.imread('data/elephant.png')\n",
    "\n",
    "# prepare an 1-D Gaussian convolution kernel\n",
    "t = np.linspace(-10, 10, 30)\n",
    "bump = np.exp(-0.1*t**2)\n",
    "bump /= np.trapz(bump) # normalize the integral to 1\n",
    "\n",
    "# make a 2-D kernel out of it\n",
    "kernel = bump[:, np.newaxis] * bump[np.newaxis, :]\n",
    "\n",
    "# padded fourier transform, with the same shape as the image\n",
    "kernel_ft = fftpack.fft2(kernel, shape=img.shape[:2], axes=(0, 1))\n",
    "\n",
    "# convolve\n",
    "img_ft = fftpack.fft2(img, axes=(0, 1))\n",
    "img2_ft = kernel_ft[:, :, np.newaxis] * img_ft\n",
    "img2 = fftpack.ifft2(img2_ft, axes=(0, 1)).real\n",
    "\n",
    "# clip values to range\n",
    "img2 = np.clip(img2, 0, 1)\n",
    "\n",
    "# plot output\n",
    "plt.imshow(img2)\n",
    "plt.show()\n",
    "\n",
    "# Further exercise (only if you are familiar with this stuff):\n",
    "#\n",
    "# A \"wrapped border\" appears in the upper left and top edges of the\n",
    "# image. This is because the padding is not done correctly, and does\n",
    "# not take the kernel size into account (so the convolution \"flows out\n",
    "# of bounds of the image\").  Try to remove this artifact.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Exercise: Denoise moon landing image\n",
    "<img src=\"data/moonlanding.png\" />\n",
    "1. Examine the provided image moonlanding.png, which is heavily contaminated with periodic noise. In this exercise, we aim to clean up the noise using the Fast Fourier Transform.\n",
    "2. Load the image using `pylab.imread()`.\n",
    "3. Find and use the 2-D FFT function in [`scipy.fftpack`](http://docs.scipy.org/doc/scipy/reference/fftpack.html#module-scipy.fftpack), and plot the spectrum (Fourier transform of) the image. Do you have any trouble visualising the spectrum? If so, why?\n",
    "4. The spectrum consists of high and low frequency components. The noise is contained in the high-frequency part of the spectrum, so set some of those components to zero (use array slicing).\n",
    "5. Apply the inverse Fourier transform to see the resulting image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Optimization and Fit: [`scipy.optimize`](http://docs.scipy.org/doc/scipy/reference/optimize.html#module-scipy.optimize)\n",
    "_Optimization_ is the problem of finding a numerical solution to a minimization or equality.\n",
    "The [`scipy.optimize`](http://docs.scipy.org/doc/scipy/reference/optimize.html#module-scipy.optimize) module provides useful algorithms for function minimization (scalar or multi-dimensional), curve fitting and root finding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import optimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. Finding the Minimum of a Scalar Function\n",
    "\n",
    "Let’s define the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return x**2 + 10*np.sin(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and plot it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = np.arange(-10, 10, 0.1)\n",
    "plt.plot(x, f(x)) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function has a _global minimum_ around -1.3 and a _local minimum_ around 3.8.\n",
    "\n",
    "The general and efficient way to find a minimum for this function is to conduct a gradient descent starting from a given initial point. The [_BFGS algorithm_](http://docs.scipy.org/doc/scipy-0.16.0/reference/generated/scipy.optimize.fmin_bfgs.html) is a good way of doing this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimize.fmin_bfgs(f, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A possible issue with this approach is that, if the function has local minima the algorithm may find these local minima instead of the global minimum depending on the initial point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimize.fmin_bfgs(f, 3, disp=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we don’t know the neighborhood of the global minimum to choose the initial point, we need to resort to costlier global optimization. To find the global minimum, we use [`scipy.optimize.basinhopping()`](http://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.basinhopping.html#scipy.optimize.basinhopping) (which combines a local optimizer with _stochastic sampling_ of starting points for the local optimizer):\n",
    "\n",
    "_New in version 0.12.0_: basinhopping was added in version 0.12.0 of Scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimize.basinhopping(f, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another available (but much less efficient) global optimizer is [`scipy.optimize.brute()`](http://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.brute.html#scipy.optimize.brute) (brute force optimization on a grid). More efficient algorithms for different classes of global optimization problems exist, but this is out of the scope of scipy. Some useful packages for global optimization are [OpenOpt](https://pypi.python.org/pypi/openopt/0.5501), [IPOPT](https://github.com/xuy/pyipopt), [PyGMO](http://esa.github.io/pygmo/) and [PyEvolve](http://pyevolve.sourceforge.net/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the _local minimum_, let’s constraint the variable to the interval (0, 10) using [`scipy.optimize.fminbound()`]():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xmin_local = optimize.fminbound(f, 0, 10)\n",
    "xmin_local"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Finding the roots of a scalar function\n",
    "\n",
    "To find a root, i.e. a point where `f(x) = 0`, of the function f above we can use for example [`scipy.optimize.fsolve()`](http://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.fsolve.html#scipy.optimize.fsolve):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "root = optimize.fsolve(f, 1)  # our initial guess is 1\n",
    "root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that only one root is found. Inspecting the plot of `f` reveals that there is a second root around -2.5. We find the exact value of it by adjusting our initial guess:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "root2 = optimize.fsolve(f, -2.5)\n",
    "root2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3. Curve Fitting\n",
    "\n",
    "Suppose we have data sampled from `f` with some noise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xdata = np.linspace(-10, 10, num=20)\n",
    "ydata = f(xdata) + np.random.randn(xdata.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if we know the functional form of the function from which the samples were drawn (`x^2 + sin(x)` in this case) but not the _amplitudes_ of the terms, we can find those by _least squares_ curve fitting. First we have to define the function to fit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f2(x, a, b):\n",
    "    return a*x**2 + b*np.sin(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can use [`scipy.optimize.curve_fit()`](http://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.curve_fit.html#scipy.optimize.curve_fit) to find `a` and `b`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "guess = [2, 2]\n",
    "params, params_covariance = optimize.curve_fit(f2, xdata, ydata, guess)\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have found the minima and roots of `f` and used curve fitting on it, we put all those resuls together in a single plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid = (-10, 10, 0.1)\n",
    "xmin_global = optimize.brute(f, (grid,))\n",
    "xmin_local = optimize.fminbound(f, 0, 10)\n",
    "root = optimize.fsolve(f, 1)  # our initial guess is 1\n",
    "root2 = optimize.fsolve(f, -2.5)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(x, f(x), 'b-', label=\"f(x)\")\n",
    "ax.plot(x, f2(x, *params), 'r--', label=\"Curve fit result\")\n",
    "xmins = np.array([xmin_global[0], xmin_local])\n",
    "ax.plot(xmins, f(xmins), 'go', label=\"Minima\")\n",
    "roots = np.array([root, root2])\n",
    "ax.plot(roots, f(roots), 'kv', label=\"Roots\")\n",
    "ax.legend()\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('f(x)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note__ In Scipy >= 0.11 unified interfaces to all minimization and root finding algorithms are available: [`scipy.optimize.minimize()`](http://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html#scipy.optimize.minimize), [`scipy.optimize.minimize_scalar()`](http://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize_scalar.html#scipy.optimize.minimize_scalar) and [`scipy.optimize.root()`](http://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.root.html#scipy.optimize.root). They allow comparing various algorithms easily through the `method` keyword.\n",
    "\n",
    "You can find algorithms with the same functionalities for multi-dimensional problems in [`scipy.optimize`](http://docs.scipy.org/doc/scipy/reference/optimize.html#module-scipy.optimize)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgba(0, 255, 0, 0.1); padding:10px;\">\n",
    "<h3>Exercise: Curve Fitting of Temperature Data</h3>\n",
    "<div style=\"padding:20px;\">\n",
    "<p>The temperature extremes in Alaska for each month, starting in January, are given by (in degrees Celcius):</p>\n",
    "<code>\n",
    "max:  17,  19,  21,  28,  33,  38, 37,  37,  31,  23,  19,  18\n",
    "min: -62, -59, -56, -46, -32, -18, -9, -13, -25, -46, -52, -58\n",
    "</code>\n",
    "<ol>\n",
    "<li>Plot these temperature extremes.</li>\n",
    "<li>Define a function that can describe min and max temperatures. Hint: this function has to have a period of 1 year. Hint: include a time offset.</li>\n",
    "<li>Fit this function to the data with <a href=\"http://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.curve_fit.html#scipy.optimize.curve_fit\">scipy.optimize.curve_fit()</a>.</li>\n",
    "<li>Plot the result. Is the fit reasonable? If not, why?</li>\n",
    "<li>Is the time offset for min and max temperatures the same within the fit accuracy?</li>\n",
    "</ol>\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgba(0, 255, 0, 0.1); padding:10px;\">\n",
    "<h3>Exercise: 2-D minimization</h3>\n",
    "<img src=\"images/scipy_optimize_sixhump.png\" alt=\"sixhump plot\">\n",
    "<div style=\"padding:20px;\">\n",
    "<p>The six-hump camelback function</p>\n",
    "<img src=\"images/sixhump_formula.png\" alt=\"sixhump formula\">\n",
    "<p>has multiple global and local minima. Find the global minima of this function.</p>\n",
    "<h4>Hints:</h4>\n",
    "<ul>\n",
    "<li>Variables can be restricted to <code>-2 &lt; x &lt; 2</code> and <code>-1 &lt; y &lt; 1.</code></li>\n",
    "<li>Use <a href=\"http://docs.scipy.org/doc/numpy/reference/generated/numpy.meshgrid.html#numpy.meshgrid\">numpy.meshgrid()</a> and <a href=\"http://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.imshow\">pylab.imshow()</a> to find visually the regions.</li>\n",
    "<li>Use <a href=\"http://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.fmin_bfgs.html#scipy.optimize.fmin_bfgs\">scipy.optimize.fmin_bfgs()</a> or another multi-dimensional minimizer.</li>\n",
    "<p>How many global minima are there, and what is the function value at those points? What happens for an initial guess of (x, y) = (0, 0)?</p>\n",
    "</ul>\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "\n",
    "def sixhump(x):\n",
    "    return (4 - 2.1*x[0]**2 + x[0]**4 / 3.) * x[0]**2 + x[0] * x[1] + (-4 + \\\n",
    "        4*x[1]**2) * x[1] **2\n",
    "\n",
    "x = np.linspace(-2, 2)\n",
    "y = np.linspace(-1, 1)\n",
    "xg, yg = np.meshgrid(x, y)\n",
    "\n",
    "#plt.figure()  # simple visualization for use in tutorial\n",
    "#plt.imshow(sixhump([xg, yg]))\n",
    "#plt.colorbar()\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "surf = ax.plot_surface(xg, yg, sixhump([xg, yg]), rstride=1, cstride=1,\n",
    "                       cmap=plt.cm.jet, linewidth=0, antialiased=False)\n",
    "\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_zlabel('f(x, y)')\n",
    "ax.set_title('Six-hump Camelback function')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Statistics and Random Numbers: [`scipy.stats`](http://docs.scipy.org/doc/scipy/reference/stats.html#module-scipy.stats)\n",
    "The module [`scipy.stats`](http://docs.scipy.org/doc/scipy/reference/stats.html#module-scipy.stats) contains statistical tools and probabilistic descriptions of random processes. Random number generators for various random process can be found in [`numpy.random`](http://docs.scipy.org/doc/numpy-1.10.0/reference/routines.random.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1. Histogram and Probability Density Function\n",
    "\n",
    "Given observations of a random process, their histogram is an estimator of the random process’s _PDF_ (_probability density function_):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = np.random.normal(size=1000)\n",
    "bins = np.arange(-4, 5)\n",
    "bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "histogram = np.histogram(a, bins=bins, normed=True)[0]\n",
    "bins = 0.5*(bins[1:] + bins[:-1])\n",
    "bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "b = stats.norm.pdf(bins)  # norm is a distribution\n",
    "\n",
    "plt.plot(bins, histogram) \n",
    "\n",
    "plt.plot(bins, b)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = np.random.normal(size=10000)\n",
    "bins = np.linspace(-5, 5, 30)\n",
    "histogram, bins = np.histogram(a, bins=bins, normed=True)\n",
    "bins = 0.5*(bins[1:] + bins[:-1])\n",
    "b = stats.norm.pdf(bins)\n",
    "plt.plot(bins, histogram)\n",
    "plt.plot(bins, b)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we know that the random process belongs to a given family of random processes, such as normal processes, we can do a _maximum-likelihood fit_ of the observations to estimate the parameters of the underlying distribution. Here we fit a normal process to the observed data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loc, std = stats.norm.fit(a)\n",
    "loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgba(0, 255, 0, 0.1); padding:10px;\">\n",
    "<h3>Exercise: Probability Distributions</h3>\n",
    "<div style=\"padding:20px;\">\n",
    "<p>Generate 1000 random variates from a gamma distribution with a shape parameter of 1, then plot a histogram from those samples. Can you plot the pdf on top (it should match)?</p>\n",
    "<p>Extra: the distributions have a number of useful methods. Explore them by reading the docstring or by using IPython tab completion. Can you find the shape parameter of 1 back by using the fit method on your random variates?</p>\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2. Percentiles\n",
    "The _median_ is the value with half of the observations below, and half above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.median(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also called the _percentile 50_, because 50% of the observation are below it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stats.scoreatpercentile(a, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we can calculate the _percentile 90_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stats.scoreatpercentile(a, 90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The percentile is an estimator of the _CDF: cumulative distribution function_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3. Statistical Tests\n",
    "A statistical test is a decision indicator. For instance, if we have two sets of observations, that we assume are generated from Gaussian processes, we can use a [T-test](https://en.wikipedia.org/wiki/Student%27s_t-test) to decide whether the two sets of observations are significantly different:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = np.random.normal(0, 1, size=100)\n",
    "b = np.random.normal(1, 1, size=10)\n",
    "stats.ttest_ind(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting output is composed of:\n",
    "* The _T statistic value_: it is a number the sign of which is proportional to the difference between the two random processes and the magnitude is related to the significance of this difference.\n",
    "* The _p value_: the probability of both processes being identical. If it is close to 1, the two process are almost certainly identical. The closer it is to zero, the more likely it is that the processes have different means."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Interpolation: [`scipy.interpolate`](http://docs.scipy.org/doc/scipy/reference/interpolate.html#module-scipy.interpolate)\n",
    "\n",
    "The [`scipy.interpolate`](http://docs.scipy.org/doc/scipy/reference/interpolate.html#module-scipy.interpolate) is useful for fitting a function from experimental data and thus evaluating points where no measure exists. The module is based on the [FITPACK Fortran subroutines](http://www.netlib.org/dierckx/index.html) from the [netlib](http://www.netlib.org/) project.\n",
    "\n",
    "By imagining experimental data close to a sine function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "measured_time = np.linspace(0, 1, 10)\n",
    "noise = (np.random.random(10)*2 - 1) * 1e-1\n",
    "measures = np.sin(2 * np.pi * measured_time) + noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [`scipy.interpolate.interp1d`](http://docs.scipy.org/doc/scipy/reference/generated/scipy.interpolate.interp1d.html#scipy.interpolate.interp1d) class can build a linear interpolation function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "linear_interp = interp1d(measured_time, measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the `scipy.interpolate.linear_interp` instance needs to be evaluated at the time of interest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "computed_time = np.linspace(0, 1, 50)\n",
    "linear_results = linear_interp(computed_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A cubic interpolation can also be selected by providing the `kind` optional keyword argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cubic_interp = interp1d(measured_time, measures, kind='cubic')\n",
    "cubic_results = cubic_interp(computed_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are now gathered on the following `Matplotlib` figure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(measured_time, measures, 'o', ms=6, label='measures')\n",
    "plt.plot(computed_time, linear_results, label='linear interp')\n",
    "plt.plot(computed_time, cubic_results, label='cubic interp')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[`scipy.interpolate.interp2d`](http://docs.scipy.org/doc/scipy/reference/generated/scipy.interpolate.interp2d.html#scipy.interpolate.interp2d) is similar to [`scipy.interpolate.interp1d`](http://docs.scipy.org/doc/scipy/reference/generated/scipy.interpolate.interp2d.html#scipy.interpolate.interp2d), but for 2-D arrays. Note that for the interp family, the computed time must stay within the measured time range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Numerical Integration: [`scipy.integrate`](http://docs.scipy.org/doc/scipy/reference/integrate.html#module-scipy.integrate)\n",
    "\n",
    "The most generic integration routine is [`scipy.integrate.quad()`](http://docs.scipy.org/doc/scipy/reference/generated/scipy.integrate.quad.html#scipy.integrate.quad):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.integrate import quad\n",
    "\n",
    "res, err = quad(np.sin, 0, np.pi/2)\n",
    "np.allclose(res, 1)\n",
    "\n",
    "np.allclose(err, 1 - res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other integration schemes are available with `fixed_quad`, `quadrature`, `romberg`.\n",
    "\n",
    "[`scipy.integrate`](http://docs.scipy.org/doc/scipy/reference/integrate.html#module-scipy.integrate) also features routines for integrating _Ordinary Differential Equations (ODE)_. In particular, [`scipy.integrate.odeint()`](http://docs.scipy.org/doc/scipy/reference/generated/scipy.integrate.odeint.html#scipy.integrate.odeint) is a general-purpose integrator using LSODA (Livermore Solver for Ordinary Differential equations with Automatic method switching for stiff and non-stiff problems), see the [ODEPACK Fortran library](http://people.sc.fsu.edu/~jburkardt/f77_src/odepack/odepack.html) for more details.\n",
    "\n",
    "`odeint` solves first-order ODE systems of the form:\n",
    "\n",
    "$$dy/dt = rhs(y1, y2, .., t0,...)$$\n",
    "\n",
    "As an introduction, let us solve the ODE `dy/dt = -2y` between `t = 0..4`, with the initial condition `y(t=0) = 1`. First the function computing the derivative of the position needs to be defined:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_derivative(ypos, time, counter_arr):\n",
    "    counter_arr += 1\n",
    "    return -2 * ypos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An extra argument `counter_arr` has been added to illustrate that the function may be called several times for a single time step, until solver convergence. The counter array is defined as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counter = np.zeros((1,), dtype=np.uint16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trajectory will now be computed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.integrate import odeint\n",
    "time_vec = np.linspace(0, 4, 40)\n",
    "yvec, info = odeint(calc_derivative, 1, time_vec,\n",
    "                    args=(counter,), full_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus the derivative function has been called more than 40 times (which was the number of time steps):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the cumulative number of iterations for each of the 10 first time steps can be obtained by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "info['nfe'][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the solver requires more iterations for the first time step. The solution `yvec` for the trajectory can now be plotted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(time_vec, yvec)\n",
    "plt.xlabel('Time [s]')\n",
    "plt.ylabel('y position [m]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another example with [`scipy.integrate.odeint()`](http://docs.scipy.org/doc/scipy/reference/generated/scipy.integrate.odeint.html#scipy.integrate.odeint) will be a damped spring-mass oscillator (2nd order oscillator). The position of a mass attached to a spring obeys the 2nd order ODE `y'' + 2 eps wo  y' + wo^2 y = 0` with `wo^2 = k/m` with `k` the spring constant, `m` the mass and `eps=c/(2 m wo)` with `c` the damping coefficient. For this example, we choose the parameters as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mass = 0.5  # kg\n",
    "kspring = 4  # N/m\n",
    "cviscous = 0.4  # N s/m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so the system will be underdamped, because:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eps = cviscous / (2 * mass * np.sqrt(kspring/mass))\n",
    "eps < 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the [`scipy.integrate.odeint()`](http://docs.scipy.org/doc/scipy/reference/generated/scipy.integrate.odeint.html#scipy.integrate.odeint) solver the 2nd order equation needs to be transformed in a system of two first-order equations for the vector `Y=(y, y')`. It will be convenient to define `nu = 2 eps * wo = c / m` and `om = wo^2 = k/m`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nu_coef = cviscous / mass\n",
    "om_coef = kspring / mass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus the function will calculate the velocity and acceleration by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_deri(yvec, time, nuc, omc):\n",
    "    return (yvec[1], -nuc * yvec[1] - omc * yvec[0])\n",
    "\n",
    "time_vec = np.linspace(0, 10, 100)\n",
    "yarr = odeint(calc_deri, (1, 0), time_vec, args=(nu_coef, om_coef))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final position and velocity are shown on the following `Matplotlib` figure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(time_vec, yarr[:, 0], label='y')\n",
    "plt.plot(time_vec, yarr[:, 1], label=\"y'\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no _Partial Differential Equations (PDE)_ solver in `Scipy`. Some Python packages for solving PDE’s are available, such as [`fipy`](http://www.ctcms.nist.gov/fipy/) or [`SfePy`](http://code.google.com/p/sfepy/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
